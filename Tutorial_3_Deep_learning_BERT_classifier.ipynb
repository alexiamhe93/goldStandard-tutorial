{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNxQz4MnXJ0xhx1vr0MZ7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexiamhe93/goldStandard-tutorial/blob/main/Tutorial_3_Deep_learning_BERT_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 3: Building a deep supervise machine learning classifier using BERT\n",
        "\n",
        "Authors: Goddard, A. & Gillespie, A.\n",
        "\n",
        "Date: January 2023\n",
        "\n",
        "This tutorial provides instructions on how to train and validate a deep supervised machine learning model using a dataset of sentences coded for misunderstandings. The sentences were produced in naturally occuring online dialogues, sourced from Reddit, Twitter, and Wikipedia Talk Pages.\n",
        "\n",
        "We use the ktrain package (Maiya, 2022) for Python (https://github.com/amaiya/ktrain) to fine-tune a BERT (Devlin et al., 2019) transformer model for classifying sentences as misunderstanding. Using a pre-trained transformer model means we can use a relatively small training dataset to make new predictions.\n",
        "\n",
        "\n",
        "This tutorial provides instructions on how to:\n",
        "1. Train a model using ktrain by fine-tuning BERT \n",
        "2. Tweak hyper-parameters to improve the classifier's performance\n",
        "3. Use under-sampling to re-balance an unbalanced dataset\n",
        "4. Save and load the trained model for use elsewhere\n",
        "\n",
        "> **NOTE** For the best performance, we recommend changing the Google Colaboratory runtime to a GPU (click *'Runtime'*, *'Change runtime type'* and select *'GPU'*). This will considerably speed up the training process for the classifier.\n",
        "\n",
        "References: \n",
        "\n",
        "Maiya, A.S. (2022). *ktrain: A Low-Code Library for Augmented Machine Learning*. (arXiv:2004.10703). arXiv. https://doi.org/10.48550/arXiv.2004.10703\n",
        "\n",
        "Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. *Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, 4171-4186. https://doi.org/10.18653/v1/N19-1423\n",
        "\n",
        "\n",
        "See also: https://colab.research.google.com/drive/1ixOZTKLz4aAa-MtC6dy_sAvc9HujQmHN#scrollTo=Y8hIFvooF4vc, https://medium.com/towards-data-science/bert-text-classification-in-3-lines-of-code-using-keras-264db7e7a358, and: https://towardsdatascience.com/ktrain-a-lightweight-wrapper-for-keras-to-help-train-neural-networks-82851ba889c\n"
      ],
      "metadata": {
        "id": "gFOZ61Ws1Ktq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages\n",
        "\n",
        "> **NOTE** Make sure to run this cell first."
      ],
      "metadata": {
        "id": "twz4GHl14mrE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLf50I0Y0_7d"
      },
      "outputs": [],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages required to train the model"
      ],
      "metadata": {
        "id": "23E8MgvT5lX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for downloading data\n",
        "import requests, zipfile, io\n",
        "# for mathematical / vectoral operations\n",
        "import numpy as np\n",
        "# for loading dataframes and spreadsheets (.csv)\n",
        "import pandas as pd\n",
        "# for loading ktrain to train the model\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "# for splitting dataset into train and test\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "VUBQ03MH5DBL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and clean data for analysis\n",
        "\n",
        "This cell downloads the gold standard dataset from github and unzips it."
      ],
      "metadata": {
        "id": "nHWbZt746YFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get( 'https://github.com/alexiamhe93/goldStandard-tutorial/blob/main/Data/Tutorial-data.zip?raw=true' ) \n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "metadata": {
        "id": "n0g3oQKn5C-e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell loads the gold standard dataset into a dataframe."
      ],
      "metadata": {
        "id": "xGQojtf61sPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv(\"Tutorial-data/Full_misunderstandings_data.csv\")"
      ],
      "metadata": {
        "id": "rtl2uC8k5C79"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean text data for analysis\n",
        "\n",
        "The below cell runs a simple cleaning protocol over the data, selecting only relevant columns for the analysis, renaming columns where appropriate, removing any empty or numeric values in the text column, and deleting any rows which were not coded for 1 or 0 in the misunderstanding column."
      ],
      "metadata": {
        "id": "EnTukRUG69Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant columns for analysis\n",
        "df0 = df0[[\"turn_id\", \"dialogue_id\", \"turn\", \"text\", \"Misunderstanding\"]]\n",
        "# delete any rows with no text\n",
        "df0 = df0[df0[\"text\"] != \"\"]\n",
        "# delete all na rows with no text\n",
        "df0 = df0[df0['text'].notna()]\n",
        "# delete any numerical rows with no text\n",
        "df0 = df0[~df0['text'].str.isnumeric()]\n",
        "# delete all values for misunderstanding not equal to zero or one\n",
        "df0 = df0[df0[\"Misunderstanding\"].isin([0,1])]\n",
        "# gives us the number of rows in loaded dataset after the cleaning process\n",
        "print(f\"The full dataset contains {len(df0)} sentences after cleaning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgcf6J2-5C4p",
        "outputId": "5594e668-e77e-492b-bcb3-d708e803f982"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The full dataset contains 21982 sentences after cleaning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cleaning process resulted in 12 rows removed. We can check the first five rows of the dataset to see if they appear as we expect them to:"
      ],
      "metadata": {
        "id": "AwFwB7dn7NNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect dataframe\n",
        "df0.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oE6Xn9we5C1g",
        "outputId": "eb43e4d1-a6a4-44ae-b659-552998e55eb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  turn_id   dialogue_id    turn  \\\n",
              "0  tid_50  group_101723  turn_1   \n",
              "1  tid_50  group_101723  turn_1   \n",
              "2  tid_50  group_101723  turn_1   \n",
              "3  tid_50  group_101723  turn_1   \n",
              "4  tid_50  group_101723  turn_1   \n",
              "\n",
              "                                                text  Misunderstanding  \n",
              "0  CMV: Territorial integrity should be taken les...                 0  \n",
              "1  However, in my opinion, the insistence on part...                 0  \n",
              "2          Take the Western Brownberg as an example.                 0  \n",
              "3  An independent state in the region has no prec...                 0  \n",
              "4  The basis of such claims is that the Spanish u...                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecdbca9b-4fda-465a-9183-6365a6e24845\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>turn_id</th>\n",
              "      <th>dialogue_id</th>\n",
              "      <th>turn</th>\n",
              "      <th>text</th>\n",
              "      <th>Misunderstanding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tid_50</td>\n",
              "      <td>group_101723</td>\n",
              "      <td>turn_1</td>\n",
              "      <td>CMV: Territorial integrity should be taken les...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tid_50</td>\n",
              "      <td>group_101723</td>\n",
              "      <td>turn_1</td>\n",
              "      <td>However, in my opinion, the insistence on part...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tid_50</td>\n",
              "      <td>group_101723</td>\n",
              "      <td>turn_1</td>\n",
              "      <td>Take the Western Brownberg as an example.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tid_50</td>\n",
              "      <td>group_101723</td>\n",
              "      <td>turn_1</td>\n",
              "      <td>An independent state in the region has no prec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tid_50</td>\n",
              "      <td>group_101723</td>\n",
              "      <td>turn_1</td>\n",
              "      <td>The basis of such claims is that the Spanish u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecdbca9b-4fda-465a-9183-6365a6e24845')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecdbca9b-4fda-465a-9183-6365a6e24845 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecdbca9b-4fda-465a-9183-6365a6e24845');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: classifier using full dataset\n",
        "\n",
        "This section trains the first model, without yet using undersampling on our dataset to improve its performance. This section also details how to identify the optimal learning-rate, a key hyper-parameter set by the researcher prior to training the model. "
      ],
      "metadata": {
        "id": "n2-qwqIn7R3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset into training and validation datasets\n",
        "\n",
        "In this section, we randomly split our data into a training dataset (70%) and a validation dataset (30%). The training set is used by the BERT classifier to identify the optimal features from the input text to best predict whether it is a misunderstanding.\n",
        "\n",
        "We stratify the data so that the frequency of misunderstandings is the same in both datasets. This is especially important for highly imbalanced datasets (such as the present dataset) as we want to ensure enough of of the target variable in the validation set."
      ],
      "metadata": {
        "id": "Y-UW_Q5U8YUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for splitting dataset into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# create vectors of texts from loaded dataset\n",
        "sentences = df0['text'].copy()\n",
        "# create vector of misunderstanding codes from loaded dataset\n",
        "misunderstanding_codes = df0['Misunderstanding'].astype(int).copy()\n",
        "\n",
        "# Split dataset\n",
        "training_sentences, validation_sentences, training_codes, validation_codes = train_test_split(sentences, # text vector\n",
        "                                                                                              misunderstanding_codes, # codes vector\n",
        "                                                                                              test_size=0.30, # size of validation set (30%)\n",
        "                                                                                              random_state=10, # random seed for replicating random split\n",
        "                                                                                              stratify=misunderstanding_codes) # stratification by the codes vector\n",
        "\n",
        "# Create train dataframe, ensuring codes are integers for the ktrain.text function\n",
        "Training_df = pd.DataFrame({\"text\": training_sentences, \"Misunderstanding\": [int(x) for x in training_codes]})\n",
        "# Create validation dataframe, ensuring codes are integers for the ktrain.text function\n",
        "Validation_df = pd.DataFrame({\"text\": validation_sentences, \"Misunderstanding\": [int(x) for x in validation_codes]})"
      ],
      "metadata": {
        "id": "cIjZur2v7bMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-process the text for use with the BERT classifier\n",
        "\n",
        "The BERT model expects the text to be preprocessed in a specific way (see Devlin et al., 2019). This can be done in the ktrain package using the `text.texts_from_df()` function. This function also lets us set the maximum number of words in a text considered by the model (`maxlen`) and the maximum number of features derived for BERT's neural network (`max_features`). \n",
        "\n",
        "The function outputs five files. Four vectors relating to the training and validation datasets (where `x` refers to the texts and `y` refers to the codes from the gold-standard dataset) and a preprocessing file denoted `preproc`. "
      ],
      "metadata": {
        "id": "ScbwQwRA9FKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create objects ready for ktrain learner object (train/test sets + preprocessing object)\n",
        "(x_train,  y_train), (x_validation, y_validation), preproc = text.texts_from_df(train_df = Training_df, # training df\n",
        "                                                                            text_column = \"text\", # text column for both training and validation dataframe\n",
        "                                                                            label_columns = [\"Misunderstanding\"], # column for the codes being predicted\n",
        "                                                                            val_df = Validation_df, # validation df\n",
        "                                                                            preprocess_mode='bert', # preprocessing mode for feature embeddings - Google's BERT\n",
        "                                                                            maxlen=64, # this is the max number of words for a document\n",
        "                                                                            max_features=50000) # size of network\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "CmcPESdE7cCw",
        "outputId": "7461af06-aa81-40a6-ad7d-2402f8b5284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['not_Misunderstanding', 'Misunderstanding']\n",
            "       not_Misunderstanding  Misunderstanding\n",
            "20550                   0.0               1.0\n",
            "15650                   1.0               0.0\n",
            "5664                    1.0               0.0\n",
            "12922                   1.0               0.0\n",
            "14970                   1.0               0.0\n",
            "['not_Misunderstanding', 'Misunderstanding']\n",
            "       not_Misunderstanding  Misunderstanding\n",
            "8557                    1.0               0.0\n",
            "14465                   1.0               0.0\n",
            "11540                   1.0               0.0\n",
            "461                     0.0               1.0\n",
            "21202                   1.0               0.0\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prime the model using ktrain. \n",
        "\n",
        "The below cell defines the model used by ktrain, which is a BERT classifier using the preprocessing instructions provided in the previous cell."
      ],
      "metadata": {
        "id": "1PZDNDp7_FW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVNdMBmc7b8s",
        "outputId": "ba1d959d-e8c4-433f-a0b6-5e0928d3f4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the learner object\n",
        "The below cell sets the learner object. The learner object is what will be continually updated during the training process and will define the features for our final classifier. This is also where we set the `batch_size` hyper-parameter, which refers to the number of coded texts observed by the algorithm before it refines its features. The original BERT paper recommends a batch size of 16 or 32 (Devlin et al., 2019). Accordingly, we set the batch size to 16."
      ],
      "metadata": {
        "id": "Gr8-cVfx_loM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=16)"
      ],
      "metadata": {
        "id": "BBbCHCZ17b0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find optimal learning rate\n",
        "\n",
        "Before training the classifier, it may be beneficial to identify the optimal learning rate. The learning rate refers to the size of the steps the algorithm uses to identify local minima using gradient-descent. The original BERT paper recommends a learning rate of 5e-5, 3e-5, or 2e-5.\n",
        "\n",
        "The following function simulates the classifier's training, increasing the learning rate iteratively, and estimating the learning loss. The learning loss is an estimate of discrepancies between the model's predicted scores and the gold-standard scores."
      ],
      "metadata": {
        "id": "x7-wfLHKA7_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.lr_find(max_epochs = 20) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNHo_QHC7bpI",
        "outputId": "7aecdaeb-9687-4f8e-d02b-46ccbfbdc38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n",
            "Epoch 1/20\n",
            "962/962 [==============================] - 248s 237ms/step - loss: 0.6067 - accuracy: 0.6075\n",
            "Epoch 2/20\n",
            "962/962 [==============================] - 227s 236ms/step - loss: 0.2572 - accuracy: 0.9218\n",
            "Epoch 3/20\n",
            "962/962 [==============================] - 227s 236ms/step - loss: 0.2074 - accuracy: 0.9252\n",
            "Epoch 4/20\n",
            "962/962 [==============================] - 227s 236ms/step - loss: 0.1623 - accuracy: 0.9379\n",
            "Epoch 5/20\n",
            "962/962 [==============================] - 227s 236ms/step - loss: 0.1328 - accuracy: 0.9462\n",
            "Epoch 6/20\n",
            "962/962 [==============================] - 227s 236ms/step - loss: 0.1039 - accuracy: 0.9596\n",
            "Epoch 7/20\n",
            "962/962 [==============================] - 227s 236ms/step - loss: 0.0917 - accuracy: 0.9644\n",
            "Epoch 8/20\n",
            "962/962 [==============================] - 227s 236ms/step - loss: 0.1323 - accuracy: 0.9541\n",
            "Epoch 9/20\n",
            "962/962 [==============================] - 24s 25ms/step - loss: 0.2849 - accuracy: 0.9246\n",
            "\n",
            "\n",
            "done.\n",
            "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next function plots the results of the previous cell's function, where we observe that the loss decreases from a learning rate of e-7 to 5e-5, but then begins increasing for learning rates above e-4. This suggests an optimal learning rate is within the range of learning rates suggested for BERT. "
      ],
      "metadata": {
        "id": "nfzgM1GwCwAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.lr_plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "0JwoiwvGCqE5",
        "outputId": "f2ced0dc-0382-44e2-fa85-a4c651d4bd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model\n",
        "\n",
        "The below function trains the new classifier. It takes as inputs the number of epochs, which refers to the number of times the algorithm observes the entire training set, and the learning rate. The original BERT paper recommends 2,3, or 4 epochs (Devlin et al., 2019) as optimal for fine-tuning BERT. We set our first model with 4 epochs and a learning rate of 2e-5.\n",
        "\n",
        "We also use a '1cycle' approach for training the classifier, a method for optimizing how the algorithm uses the learning rate during training (see Smith, 2018 for details).   \n",
        "\n",
        "References:\n",
        "\n",
        "Smith, L. N. (2018). *A disciplined approach to neural network hyper-parameters: Part 1--learning rate, batch size, momentum, and weight decay*. arXiv preprint arXiv:1803.09820.\n"
      ],
      "metadata": {
        "id": "44AJ8DCZCuyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_onecycle(2e-5, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6hjwYSkKUXU",
        "outputId": "97e217e6-bd4f-44fd-d989-375367801892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/4\n",
            "962/962 [==============================] - 250s 238ms/step - loss: 0.2202 - accuracy: 0.9093\n",
            "Epoch 2/4\n",
            "962/962 [==============================] - 228s 237ms/step - loss: 0.1350 - accuracy: 0.9460\n",
            "Epoch 3/4\n",
            "962/962 [==============================] - 228s 237ms/step - loss: 0.0695 - accuracy: 0.9726\n",
            "Epoch 4/4\n",
            "962/962 [==============================] - 228s 237ms/step - loss: 0.0165 - accuracy: 0.9950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2497f0a0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate model\n",
        "\n",
        "To check the model's accuracy, we generate a classification report with four accuracy statistics based on the true/false positives and negatives for the classifier. A true positive is where the predicted code equals 1 and the gold-standard code equals 1; a true negative is where the predicted code equals 0 and the gold-standard code equals 0; a false positive is where the predicted code equals 0 but the gold-standard code equals 1; and, finally, a false negative is where the predicted code equals 1 but the gold-standard code equals 0. The four basic accuracy statistics are:\n",
        "\n",
        "*   Accuracy: the ratio of correct predictions \n",
        "*   Precision: the ratio of true positives to true positives and false positives\n",
        "*   Recall: the ratio of true positives to true positives and false negatives\n",
        "*   F1 score: harmonic mean of precision and recall"
      ],
      "metadata": {
        "id": "9F4FgR5uOBlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.validate(val_data=(x_validation, y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIcNvr_iKUUm",
        "outputId": "aa18bbbc-e28e-43b2-dc06-8782513b9127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207/207 [==============================] - 35s 146ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      6080\n",
            "           1       0.64      0.56      0.60       515\n",
            "\n",
            "    accuracy                           0.94      6595\n",
            "   macro avg       0.80      0.77      0.78      6595\n",
            "weighted avg       0.94      0.94      0.94      6595\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5915,  165],\n",
              "       [ 225,  290]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model performs fairly poorly (F1-score = 0.60), with moderate precision (0.64) but weak recall (0.56). The accuracy is inflated (0.94) due to the number of no misunderstandings in the dataset, meaning that the classifier can perform relatively well only classifying data into this class. "
      ],
      "metadata": {
        "id": "we2rseMMWDgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: undersampling to increase model performance\n",
        "\n",
        "In this section, we train a new model with the same hyper-parameters (batch size, number of epochs, and learning rate), but rebalance our dataset using undersampling.\n",
        "\n",
        "Our dataset is highly skewed towards no misunderstandings:\n"
      ],
      "metadata": {
        "id": "C_4FH3J0OxoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pct_mis = round(len(df0[df0[\"Misunderstanding\"]==1])/len(df0) *100)\n",
        "print(f\"Percentage of sentences that are misunderstandings {pct_mis}%\\nPercentage of sentences that are not misunderstandings: {100-pct_mis}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE5eU0rSKUR6",
        "outputId": "c44527b4-3a9f-4da2-9739-8734bb06853e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of sentences that are misunderstandings 8\n",
            "Percentage of sentences that are not misunderstandings: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Undersampling is the process of randomly deleting example texts from the majority class in order to re-balance the dataset. Researchers may also use oversampling, which involves randomly re-sampling cases of the minority class (i.e. misunderstandings) to balance the data. We chose undersampling as, even though we lose discriminating information (see Susan & Kumar, 2021), we reduce the chance of overfitting to the training data due to the limited number of misunderstandings. \n",
        "\n",
        "We also remove any noisey codes in the gold-standard dataset by deleting any duplicate texts. This removes any texts that potentially have contradicting codes (e.g. a sentence coded for misunderstanding in one instance and no misunderstanding in another instance).\n",
        "\n",
        "After a number of different models, we found a 2:1 no misunderstandings to misunderstandings ratio provided the optimal undersampling for our classifier. "
      ],
      "metadata": {
        "id": "4y2tdkpqPZ1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any duplicate text files - this prevents any ambiguously coded rows\n",
        "df1 = df0.drop_duplicates(\"text\")\n",
        "print(f\"Number of texts with duplicates {len(df0)}\\nNumber of texts without duplicates {len(df1)}\\nRows removed: {len(df0)-len(df1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzUuFERxKUO_",
        "outputId": "e8f306fe-44d8-44a1-836a-a4ef31a2db3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts with duplicates 21982\n",
            "Number of texts without duplicates 20984\n",
            "Rows removed: 998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select misunderstanding turns\n",
        "mis_df1 = df1[df1[\"Misunderstanding\"]==1]\n",
        "# select non-misunderstanding turns; stating the random state ensures reproducibility\n",
        "notmis_df1 = df1[df1[\"Misunderstanding\"]==0].sample(2*len(mis_df1), random_state=10) \n",
        "# create new undersampling dataframe\n",
        "df2 = pd.concat([mis_df1, notmis_df1])"
      ],
      "metadata": {
        "id": "OR0FOiHSKUGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is now much smaller, but considerably more balanced:"
      ],
      "metadata": {
        "id": "XOTFUJ9wTK10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"New dataframe size {len(df2)}\\nRows removed from original dataset: {len(df0)-len(df2)}\")\n",
        "pct_mis2 = round(len(df2[df2[\"Misunderstanding\"]==1])/len(df2) *100)\n",
        "print(f\"Percentage of sentences that are misunderstandings {pct_mis2}%\\nPercentage of sentences that are not misunderstandings: {100-pct_mis2}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX3orO6hT8TE",
        "outputId": "28cae124-9a97-4228-8959-d492ba8c13f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dataframe size 5073\n",
            "Rows removed from original dataset: 16909\n",
            "Percentage of sentences that are misunderstandings 33%\n",
            "Percentage of sentences that are not misunderstandings: 67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create new training and vaidation dataset & preprocess"
      ],
      "metadata": {
        "id": "avp2zDZVUPoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create vectors of texts from loaded dataset\n",
        "sentences2 = df2['text'].copy()\n",
        "# create vector of misunderstanding codes from loaded dataset\n",
        "misunderstanding_codes2 = df2['Misunderstanding'].astype(int).copy()\n",
        "\n",
        "# Split dataset\n",
        "training_sentences2, validation_sentences2, training_codes2, validation_codes2 = train_test_split(sentences2, # text vector\n",
        "                                                                                              misunderstanding_codes2, # codes vector\n",
        "                                                                                              test_size=0.30, # size of validation set (30%)\n",
        "                                                                                              random_state=10, # random seed for replicating random split\n",
        "                                                                                              stratify=misunderstanding_codes2) # stratification by the codes vector\n",
        "\n",
        "# Create train dataframe, ensuring codes are integers for the ktrain.text function\n",
        "Training_df2 = pd.DataFrame({\"text\": training_sentences2, \"Misunderstanding\": [int(x) for x in training_codes2]})\n",
        "# Create validation dataframe, ensuring codes are integers for the ktrain.text function\n",
        "Validation_df2 = pd.DataFrame({\"text\": validation_sentences2, \"Misunderstanding\": [int(x) for x in validation_codes2]})\n",
        "\n",
        "# Create objects ready for ktrain learner object (train/test sets + preprocessing object)\n",
        "(x_train2,  y_train2), (x_validation2, y_validation2), preproc2 = text.texts_from_df(train_df = Training_df2, # training df\n",
        "                                                                            text_column = \"text\", # text column for both training and validation dataframe\n",
        "                                                                            label_columns = [\"Misunderstanding\"], # column for the codes being predicted\n",
        "                                                                            val_df = Validation_df2, # validation df\n",
        "                                                                            preprocess_mode='bert', # preprocessing mode for feature embeddings - Google's BERT\n",
        "                                                                            maxlen=64, # this is the max number of words for a document\n",
        "                                                                            max_features=50000) # size of network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "US9nJQvvUTWw",
        "outputId": "c05e5ee0-af58-488c-c42c-e0961fae4a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['not_Misunderstanding', 'Misunderstanding']\n",
            "       not_Misunderstanding  Misunderstanding\n",
            "11985                   1.0               0.0\n",
            "15974                   0.0               1.0\n",
            "10561                   1.0               0.0\n",
            "14079                   1.0               0.0\n",
            "4781                    1.0               0.0\n",
            "['not_Misunderstanding', 'Misunderstanding']\n",
            "       not_Misunderstanding  Misunderstanding\n",
            "2205                    1.0               0.0\n",
            "1521                    1.0               0.0\n",
            "15841                   1.0               0.0\n",
            "12437                   1.0               0.0\n",
            "9960                    1.0               0.0\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model 2 using undersampled data"
      ],
      "metadata": {
        "id": "sjVp6AHzS1lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = text.text_classifier('bert', train_data=(x_train2, y_train2), preproc=preproc2)\n",
        "learner = ktrain.get_learner(model, train_data=(x_train2, y_train2), batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfyTlIH0UHC5",
        "outputId": "daa35628-1c05-4e0d-b333-bd5e3dd14784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_onecycle(2e-5, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mILTlDPvUHkA",
        "outputId": "94378710-64eb-4ee5-9b8d-89611e58c804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/4\n",
            "222/222 [==============================] - 70s 221ms/step - loss: 0.5034 - accuracy: 0.7482\n",
            "Epoch 2/4\n",
            "222/222 [==============================] - 51s 231ms/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 3/4\n",
            "222/222 [==============================] - 51s 230ms/step - loss: 0.1898 - accuracy: 0.9259\n",
            "Epoch 4/4\n",
            "222/222 [==============================] - 51s 231ms/step - loss: 0.0615 - accuracy: 0.9809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate model 2"
      ],
      "metadata": {
        "id": "E3ZiTD7wWzjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.validate(val_data=(x_validation2, y_validation2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OLxItkCUHhS",
        "outputId": "8bd3a610-38e6-4a92-eaab-2aa6d42dac08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 11s 141ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91      1015\n",
            "           1       0.82      0.79      0.81       507\n",
            "\n",
            "    accuracy                           0.87      1522\n",
            "   macro avg       0.86      0.85      0.86      1522\n",
            "weighted avg       0.87      0.87      0.87      1522\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[929,  86],\n",
              "       [106, 401]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2 performs much better than Model 1 (F1-score = 0.81), with a slightly higher precision (0.82) than recall (0.79). This suggests that are classifier is marginally better at correctly predicting a sentence as a misunderstanding (identifying true positives) than identifying all instances of misunderstanding (identifying true negatives)."
      ],
      "metadata": {
        "id": "4FGgx37CYAv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict new data using Model 2\n",
        "\n",
        "Now that we have a trained model, we can sense-check it by predicting whether sentences we suggest are misunderstandings or not. The next cell shows how to load the predictor using a simple `Predictor.predict()` function based on the BERT classifier we have just fine-tuned."
      ],
      "metadata": {
        "id": "L-ogaL9RXmxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a predictor tool\n",
        "Predictor = ktrain.get_predictor(learner.model, preproc2)\n",
        "# check the classes are correct\n",
        "Predictor.predict(\"I don't understand you.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Te_GciivUHeL",
        "outputId": "c740c73a-d070-4b90-8534-9c95d9a7aa91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Misunderstanding'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE** The next cells can be used to save the model to disk and recalling it for future use. "
      ],
      "metadata": {
        "id": "3hjhjKEKsssZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saves model to disk\n",
        "ktrain.get_predictor(model, preproc2).save('trained_models/mis_model_5')\n",
        "# reloads model into the notebook\n",
        "Predictor = ktrain.load_predictor('trained_models/mis_model_5')"
      ],
      "metadata": {
        "id": "vqf8N59Xp9dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create a set of 15 sentences to sense-check the new prediction tool to see if it passes a face-validity check. The 15 sentences include five sentences we would classify as misunderstanding, five we would classify as not misunderstanding, and five edge cases that skew slightly to either misunderstanding or not. "
      ],
      "metadata": {
        "id": "h9gDxyA1pZBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of sentences, 5 misunderstandings, 5 non misunderstandings, and 5 edge cases\n",
        "user_generated_sentences = [\"That's not what I meant\", \"I don't get your point\", \n",
        "                            \"I said this above, PLEASE try to read my points\",\n",
        "                            \"What do you mean?\", \"That's not what I meant.\",\n",
        "                            \"My favourite shoes are Nikes\",\"My least favourite thing to do is watch TV\",\n",
        "                            \"It's really cold outside.\", \"I know how you feel.\", \"I get it.\",\n",
        "                            \"I get that, but why bother?\", \n",
        "                            \"I understand your point on cats, but what is your stance on dogs?\",\n",
        "                            \"I'm glad we've not misunderstood each other.\", \n",
        "                            \"So I said to him, 'I don't get it', but I actually did understand\",\n",
        "                            \"Don't get me wrong, I love cats.\"]\n",
        "# List of the true codes decided by researcher\n",
        "true_codes = [\"Misunderstanding\", \"Misunderstanding\", \"Misunderstanding\", \n",
        "              \"Misunderstanding\", \"Misunderstanding\", \"Not misunderstanding\",\n",
        "              \"Not misunderstanding\",\"Not misunderstanding\",\"Not misunderstanding\",\n",
        "              \"Not misunderstanding\",\"Misunderstanding (edge case)\", \n",
        "              \"Misunderstanding (edge case)\", \"Not Misunderstanding (edge case)\", \n",
        "              \"Not Misunderstanding (edge case)\", \"Not Misunderstanding (edge case)\"]\n",
        "\n",
        "# Run the predictor on the user generated sentences\n",
        "predicted_codes = [Predictor.predict(s) for s in user_generated_sentences]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eQ42A1KoBFL",
        "outputId": "4c2d1065-f4a8-4c35-dadd-b52d3bb65db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results as a dataframe\n",
        "\n",
        "pd.DataFrame({\"User sentences\": user_generated_sentences,\n",
        "              \"True codes\": true_codes, \"Classifier codes\": predicted_codes})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "KCUPhbuHq1Ii",
        "outputId": "6a4dd6b9-6441-4783-b492-4ed88592d3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       User sentences  \\\n",
              "0                             That's not what I meant   \n",
              "1                              I don't get your point   \n",
              "2     I said this above, PLEASE try to read my points   \n",
              "3                                   What do you mean?   \n",
              "4                            That's not what I meant.   \n",
              "5                        My favourite shoes are Nikes   \n",
              "6          My least favourite thing to do is watch TV   \n",
              "7                           It's really cold outside.   \n",
              "8                                I know how you feel.   \n",
              "9                                           I get it.   \n",
              "10                        I get that, but why bother?   \n",
              "11  I understand your point on cats, but what is y...   \n",
              "12       I'm glad we've not misunderstood each other.   \n",
              "13  So I said to him, 'I don't get it', but I actu...   \n",
              "14                   Don't get me wrong, I love cats.   \n",
              "\n",
              "                          True codes      Classifier codes  \n",
              "0                   Misunderstanding      Misunderstanding  \n",
              "1                   Misunderstanding      Misunderstanding  \n",
              "2                   Misunderstanding      Misunderstanding  \n",
              "3                   Misunderstanding      Misunderstanding  \n",
              "4                   Misunderstanding      Misunderstanding  \n",
              "5               Not misunderstanding  not_Misunderstanding  \n",
              "6               Not misunderstanding  not_Misunderstanding  \n",
              "7               Not misunderstanding  not_Misunderstanding  \n",
              "8               Not misunderstanding  not_Misunderstanding  \n",
              "9               Not misunderstanding  not_Misunderstanding  \n",
              "10      Misunderstanding (edge case)      Misunderstanding  \n",
              "11      Misunderstanding (edge case)      Misunderstanding  \n",
              "12  Not Misunderstanding (edge case)      Misunderstanding  \n",
              "13  Not Misunderstanding (edge case)      Misunderstanding  \n",
              "14  Not Misunderstanding (edge case)  not_Misunderstanding  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5028bcb-4bf3-4318-b61c-06e62cba0ed9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User sentences</th>\n",
              "      <th>True codes</th>\n",
              "      <th>Classifier codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>That's not what I meant</td>\n",
              "      <td>Misunderstanding</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I don't get your point</td>\n",
              "      <td>Misunderstanding</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I said this above, PLEASE try to read my points</td>\n",
              "      <td>Misunderstanding</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What do you mean?</td>\n",
              "      <td>Misunderstanding</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That's not what I meant.</td>\n",
              "      <td>Misunderstanding</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>My favourite shoes are Nikes</td>\n",
              "      <td>Not misunderstanding</td>\n",
              "      <td>not_Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>My least favourite thing to do is watch TV</td>\n",
              "      <td>Not misunderstanding</td>\n",
              "      <td>not_Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>It's really cold outside.</td>\n",
              "      <td>Not misunderstanding</td>\n",
              "      <td>not_Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I know how you feel.</td>\n",
              "      <td>Not misunderstanding</td>\n",
              "      <td>not_Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I get it.</td>\n",
              "      <td>Not misunderstanding</td>\n",
              "      <td>not_Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I get that, but why bother?</td>\n",
              "      <td>Misunderstanding (edge case)</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I understand your point on cats, but what is y...</td>\n",
              "      <td>Misunderstanding (edge case)</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I'm glad we've not misunderstood each other.</td>\n",
              "      <td>Not Misunderstanding (edge case)</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>So I said to him, 'I don't get it', but I actu...</td>\n",
              "      <td>Not Misunderstanding (edge case)</td>\n",
              "      <td>Misunderstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Don't get me wrong, I love cats.</td>\n",
              "      <td>Not Misunderstanding (edge case)</td>\n",
              "      <td>not_Misunderstanding</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5028bcb-4bf3-4318-b61c-06e62cba0ed9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5028bcb-4bf3-4318-b61c-06e62cba0ed9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5028bcb-4bf3-4318-b61c-06e62cba0ed9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that for the ten examples we consider clear misunderstanding or clear non misunderstandings, the classifier performs as expected, classifying all ten into the correct class. However, for the edge cases (sentences 10-14), the classifier incorrectly classifies 2/5 sentences. The following paragraph explains the edge cases and how the algorithm succeeds and fails to differentiate between them.\n",
        "\n",
        "Sentences 10 and 11 are examples of misunderstandings following a statement of misunderstanding in the same sentence. Here, the classifier correctly predicts the construct. Sentence 12 is a statement that two interacting individuals have not misunderstood each other. The classifier incorrectly classifies this as a misunderstanding. Sentence 13 is a quoted statement of misunderstanding, with the imagined speaker saying they were actually lying about misunderstanding. Again, the classifier fails to correctly identify this statement as not a misunderstanding. Finally, sentence 14 is hedging (\"don't get me wrong\") by clarifying the meaning of their next or previous sentences. Here, the classifier correctly identifies this as not misunderstanding. "
      ],
      "metadata": {
        "id": "53zlJXCrq8Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "In this tutorial, we provided instructions on how to fine-tune a BERT classifier for predicting misunderstandings, a social-psychological construct, in sentences sampled from online dialogues. Our final classifier (Model 2) performs moderately well (F1-score = 0.81), but, following a sense-check for face-validity, was found to struggle with edge-cases of the phenomena. This may be in part from noise in the gold-standard dataset used, which had moderate inter-rater reliability (Krippendorf's Alpha = 0.80). This means that certain misunderstandings in the gold-standard dataset may have been missed or incorrectly coded in the first instance. The trained classifier is only as good as the gold-standard dataset used to train it.\n",
        "\n",
        "The tutorial is limited in its demonstration of a binary classifier, however ktrain and BERT can both handle multi-label categorical classes. Furthermore, the tutorial makes an assumption that the sentences in the dataset are independent which they are not. Instead, sentences belong to a larger text (e.g. a comment on Reddit or a Tweet) and to a dialogue. This added sequential information is ignored in the training of the classifier but its inclusion in future models may lead to increased accuracy and better reflect the gold-standard codes from the dataset."
      ],
      "metadata": {
        "id": "fjPyzfDCZrWz"
      }
    }
  ]
}